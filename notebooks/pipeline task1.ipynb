{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10835,"status":"ok","timestamp":1727973341032,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"rJmtB8gr2LAY","outputId":"bc51370f-bad4-42ef-fefd-76171eb3e02d"},"outputs":[],"source":["from typing import List, Union\n","\n","import nltk #Natural Language Toolkit\n","import numpy as np\n","import pandas as pd\n","from nltk.corpus import twitter_samples\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import TweetTokenizer\n","\n","from sklearn.metrics import classification_report\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","## Process data\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","import re\n","import string\n","## model\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","import lightgbm as lgb\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1934,"status":"ok","timestamp":1727973342963,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"ab139bLi2SnC","outputId":"d5bcefa2-8a57-4493-c5a5-9c781e28f7df"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package twitter_samples to\n","[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package twitter_samples is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('twitter_samples')\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2207,"status":"ok","timestamp":1727973345167,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"B4zosb6I2Y8D"},"outputs":[],"source":["all_positive_tweets_sen = twitter_samples.strings('positive_tweets.json')\n","all_negative_tweets_sen = twitter_samples.strings('negative_tweets.json')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":17709,"status":"ok","timestamp":1727973362873,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"7mnFaUGVTlrX"},"outputs":[],"source":["def process_tweet(tweet: str) -> List[str]:\n","    \"\"\"\n","    Processes a tweet by cleaning, tokenizing, and stemming the words.\n","\n","    Parameters:\n","    - tweet: A string representing a tweet.\n","\n","    Returns:\n","    - tweets_clean: A list of words containing the processed tweet.\n","    \"\"\"\n","    stemmer = PorterStemmer()\n","    stopwords_english = stopwords.words('english')\n","\n","    # remove stock market tickers like $GE\n","    tweet = re.sub(r'\\$\\w*', '', tweet)\n","    # remove old style retweet text \"RT\"\n","    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n","    # remove hyperlinks\n","    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n","    # remove hashtags (only removing the hash # sign)\n","    tweet = re.sub(r'#', '', tweet)\n","\n","    # tokenize tweets\n","    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n","    tweet_tokens = tokenizer.tokenize(tweet)\n","\n","    tweets_clean = []\n","    for word in tweet_tokens:\n","        if word not in stopwords_english and word not in string.punctuation:  # remove stopwords and punctuation\n","            stem_word = stemmer.stem(word)\n","            tweets_clean.append(stem_word)\n","\n","    return tweets_clean\n","\n","# Assuming all_positive_tweets_sen and all_negative_tweets_sen are lists of tweet strings\n","all_positive_tweets = [process_tweet(tweet) for tweet in all_positive_tweets_sen]\n","all_negative_tweets = [process_tweet(tweet) for tweet in all_negative_tweets_sen]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1727973362873,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"c0qr-Grd2a56","outputId":"9490fdc3-384d-40c1-9f22-1e438591b0ac"},"outputs":[{"data":{"text/plain":["5000"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len(all_positive_tweets)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1727973362874,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"VWXFe1aI26yI","outputId":"8c086ab2-91dc-4534-c2ec-6ed1cef52f3f"},"outputs":[{"data":{"text/plain":["5000"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["len(all_negative_tweets)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1727973362874,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"C3GQL5x531Rd"},"outputs":[],"source":["test_pos = all_positive_tweets[4000:]\n","train_pos = all_positive_tweets[:4000]\n","test_neg = all_negative_tweets[4000:]\n","train_neg = all_negative_tweets[:4000]\n","\n","train_x = train_pos + train_neg\n","test_x = test_pos + test_neg"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1727973362874,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"qsuMq5Ro31a8"},"outputs":[],"source":["y_train = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n","y_test = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1727973362874,"user":{"displayName":"Tâm Trịnh","userId":"04806761724989912665"},"user_tz":-420},"id":"LzorzL0o5g_4","outputId":"cdfc015d-a936-4ad3-c2ef-6cf20862921b"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_y.shape = (8000, 1)\n","test_y.shape = (2000, 1)\n"]}],"source":["# Print the shape train and test sets\n","print(\"train_y.shape = \" + str(y_train.shape))\n","print(\"test_y.shape = \" + str(y_test.shape))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["X_train = [' '.join(tokens) for tokens in train_x]\n","X_test = [' '.join(tokens) for tokens in test_x]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def error_analysis(pipeline: Pipeline, \n","                   X_test: Union[np.ndarray, List[str]], \n","                   y_test: np.ndarray, \n","                   sentences: List[str]) -> pd.DataFrame:\n","    \"\"\"\n","    Perform error analysis on the model's predictions using the entire pipeline.\n","\n","    Parameters:\n","    - pipeline: The trained pipeline containing vectorizer and model.\n","    - X_test: The test features (original text data).\n","    - y_test: The true labels for the test set.\n","    - sentences: List or array containing the original sentences or data points.\n","\n","    Returns:\n","    - DataFrame with columns: ['sentence', 'predicted_class', 'real_class']\n","      showing the misclassified data points.\n","    \"\"\"\n","    # Make predictions using the pipeline\n","    y_pred = pipeline.predict(X_test)\n","\n","    # Create a DataFrame for error analysis\n","    df_errors = pd.DataFrame({\n","        'sentence': sentences,\n","        'predicted_class': y_pred,\n","        'real_class': y_test.flatten()  # Ensure this is flattened\n","    })\n","\n","    # Filter rows where the prediction is incorrect\n","    df_errors = df_errors[df_errors['predicted_class'] != df_errors['real_class']]\n","\n","    return df_errors"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Logistic Regression Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.99      1.00      1000\n","         1.0       1.00      1.00      1.00      1000\n","\n","    accuracy                           1.00      2000\n","   macro avg       1.00      1.00      1.00      2000\n","weighted avg       1.00      1.00      1.00      2000\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"name":"stdout","output_type":"stream","text":["SVC Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      1.00      1.00      1000\n","         1.0       1.00      1.00      1.00      1000\n","\n","    accuracy                           1.00      2000\n","   macro avg       1.00      1.00      1.00      2000\n","weighted avg       1.00      1.00      1.00      2000\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return fit_method(estimator, *args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Random Forest Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.99      1.00      1000\n","         1.0       0.99      1.00      1.00      1000\n","\n","    accuracy                           1.00      2000\n","   macro avg       1.00      1.00      1.00      2000\n","weighted avg       1.00      1.00      1.00      2000\n","\n","Naive Bayes Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.96      0.96      1000\n","         1.0       0.96      0.96      0.96      1000\n","\n","    accuracy                           0.96      2000\n","   macro avg       0.96      0.96      0.96      2000\n","weighted avg       0.96      0.96      0.96      2000\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n","c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","c:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 4000, number of negative: 4000\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010174 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 9218\n","[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 407\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","LightGBM Classification Report:\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.99      1.00      1000\n","         1.0       0.99      1.00      1.00      1000\n","\n","    accuracy                           1.00      2000\n","   macro avg       1.00      1.00      1.00      2000\n","weighted avg       1.00      1.00      1.00      2000\n","\n"]}],"source":["# Store error DataFrames for all models\n","all_errors = {}\n","\n","#Model\n","models = {\n","    'Logistic Regression': LogisticRegression(),\n","    'SVC': SVC(),\n","    'Random Forest': RandomForestClassifier(),\n","    'Naive Bayes': MultinomialNB(),\n","    'LightGBM': lgb.LGBMClassifier()\n","}\n","for model_name, model in models.items():\n","    # Create the pipeline\n","    pipeline = Pipeline([\n","        ('tfidf', TfidfVectorizer(tokenizer=lambda x: x.split(), sublinear_tf=True)),\n","        ('classifier', model)\n","    ])\n","    # Fit the model\n","    pipeline.fit(X_train, y_train)\n","\n","    # Predictions and classification report\n","    y_pred = pipeline.predict(X_test)\n","    print(f\"{model_name} Classification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","    # Perform error analysis\n","    errors = error_analysis(pipeline, X_test, y_test, test_x)  # Pass test_x as the sentences\n","    all_errors[model_name] = errors  # Store the errors for each model\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>predicted_class</th>\n","      <th>real_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>753</th>\n","      <td>[park, get, sunlight]</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1298</th>\n","      <td>[u, prob, fun, david]</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1544</th>\n","      <td>[pat, jay]</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1756</th>\n","      <td>[belov, grandmoth]</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1773</th>\n","      <td>[that, life, get, call, peopl, havent, seen, 2...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1853</th>\n","      <td>[sr, financi, analyst, expedia, inc, bellevu, ...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               sentence  predicted_class  \\\n","753                               [park, get, sunlight]              0.0   \n","1298                              [u, prob, fun, david]              1.0   \n","1544                                         [pat, jay]              1.0   \n","1756                                 [belov, grandmoth]              1.0   \n","1773  [that, life, get, call, peopl, havent, seen, 2...              1.0   \n","1853  [sr, financi, analyst, expedia, inc, bellevu, ...              1.0   \n","\n","      real_class  \n","753          1.0  \n","1298         0.0  \n","1544         0.0  \n","1756         0.0  \n","1773         0.0  \n","1853         0.0  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["#Loading the error\n","logistic_errors = all_errors['Logistic Regression']\n","logistic_errors "]},{"cell_type":"markdown","metadata":{},"source":["# Tuning"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def error_analysis_tuning(model, \n","                          X_test: Union[np.ndarray, List[str]], \n","                          y_test: np.ndarray, \n","                          sentences: List[str]) -> pd.DataFrame:\n","    \"\"\"\n","    Perform error analysis on the model's predictions.\n","\n","    Parameters:\n","    - model: The trained model to evaluate.\n","    - X_test: The test features.\n","    - y_test: The true labels for the test set.\n","    - sentences: List or array containing the original sentences or data points.\n","\n","    Returns:\n","    - DataFrame with columns: ['sentence', 'predicted_class', 'real_class']\n","      showing the misclassified data points.\n","    \"\"\"\n","    # Make predictions\n","    y_pred = model.predict(X_test).tolist()\n","    y_pred = [int(pred) for pred in y_pred]\n","    y_test = y_test.flatten().astype(int).tolist()\n","    \n","    # Create a DataFrame for error analysis\n","    df_errors = pd.DataFrame({\n","        'sentence': sentences,        # Sentences or data points\n","        'predicted_class': y_pred,    # Model predictions\n","        'real_class': y_test          # True labels\n","    })\n","\n","    # Filter rows where the prediction is incorrect\n","    df_errors = df_errors[df_errors['predicted_class'] != df_errors['real_class']]\n","\n","    return df_errors"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m rf_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier__bootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     12\u001b[0m rf_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(rf_pipeline, rf_param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m rf_grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Best parameters and score for Random Forest\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for Random Forest:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rf_grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\PC\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["rf_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(tokenizer=lambda x: x.split(), sublinear_tf=True)),\n","    ('classifier', RandomForestClassifier(random_state=42))\n","])\n","rf_param_grid = {\n","    'classifier__n_estimators': [100, 200, 300, 400, 500],\n","    'classifier__max_features': ['sqrt', 'log2', None],\n","    'classifier__max_depth': [None, 10, 20, 30, 40, 50],\n","    'classifier__min_samples_split': [2, 5, 10],\n","    'classifier__min_samples_leaf': [1, 2, 4],\n","    'classifier__bootstrap': [True, False]\n","}\n","\n","rf_grid_search = GridSearchCV(rf_pipeline, rf_param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n","rf_grid_search.fit(X_train, y_train)\n","# Best parameters and score for Random Forest\n","print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n","print(\"Best score for Random Forest:\", rf_grid_search.best_score_)\n","\n","# Predictions and classification report for Random Forest\n","rf_best_model = rf_grid_search.best_estimator_\n","rf_y_pred = rf_best_model.predict(X_test)\n","print(\"Random Forest Classification Report:\")\n","print(classification_report(y_test, rf_y_pred))\n","\n","error_analysis_tuning(rf_best_model, X_test, y_test, test_x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lgb_pipeline = Pipeline([\n","    ('tfidf', TfidfVectorizer(tokenizer=lambda x: x.split(), sublinear_tf=True)),\n","    ('classifier', lgb.LGBMClassifier(random_state=42))\n","])\n","lgb_param_grid = {\n","    'classifier__num_leaves': np.arange(20, 150, 5),\n","    'classifier__max_depth': np.arange(3, 15, 1),\n","    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n","    'classifier__n_estimators': np.arange(50, 300, 10),\n","    'classifier__boosting_type': ['gbdt', 'dart'],\n","    'classifier__min_child_samples': np.arange(1, 20, 1),\n","    'classifier__subsample': [0.6, 0.8, 1.0]\n","}\n","lgb_grid_search = GridSearchCV(lgb_pipeline, lgb_param_grid, cv=3, scoring='accuracy', verbose=1)\n","lgb_grid_search.fit(X_train, y_train)\n","\n","print(\"Best parameters for Random Forest:\", lgb_grid_search.best_params_)\n","print(\"Best score for Random Forest:\", lgb_grid_search.best_score_)\n","\n","lgb_best_model = lgb_grid_search.best_estimator_\n","lgb_y_pred = lgb_best_model.predict(X_test)\n","print(\"Random Forest Classification Report:\")\n","print(classification_report(y_test, rf_y_pred))\n","\n","error_analysis_tuning(lgb_best_model, X_test, y_test, test_x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO+zL+W99Gkd0iactQ2IC75","provenance":[{"file_id":"1oRyLQO7zFWy-DhBsg5yntCuUFHul8h4K","timestamp":1727973292270}]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
