{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import logging\n",
    "import yaml\n",
    "import warnings\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hải Nam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline modules from module\n",
    "from module.preprocess import Preprocessor\n",
    "from module.train import Trainer\n",
    "from module.evaluate import ModelEvaluator\n",
    "from module.tuning import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings (Optional)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration from the YAML file\n",
    "config_path = './module/config.yaml'\n",
    "with open(config_path, 'r') as stream:\n",
    "    config = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for the notebook\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to run the pipeline\n",
    "def run_pipeline():\n",
    "    logging.info(\"Pipeline execution started.\")\n",
    "\n",
    "    # Step 1: Data Ingestion\n",
    "    import nltk\n",
    "    from nltk.corpus import twitter_samples\n",
    "    nltk.download('twitter_samples')\n",
    "\n",
    "    all_positive_tweets_sen = twitter_samples.strings('positive_tweets.json')\n",
    "    all_negative_tweets_sen = twitter_samples.strings('negative_tweets.json')\n",
    "    logging.info(\"Data loading completed.\")\n",
    "\n",
    "    # Step 2: Preprocessing\n",
    "    logging.info(\"Preprocessing started.\")\n",
    "    preprocessor = Preprocessor()\n",
    "    train_x, test_x, y_train, y_test = preprocessor.preprocess_data(\n",
    "        all_positive_tweets_sen, all_negative_tweets_sen)\n",
    "\n",
    "    X_train = [' '.join(tokens) for tokens in train_x]\n",
    "    X_test = [' '.join(tokens) for tokens in test_x]\n",
    "    logging.info(\"Preprocessing finished.\")\n",
    "\n",
    "    # Step 3: Model Training\n",
    "    logging.info(\"Model training started.\")\n",
    "    trainer = Trainer()\n",
    "    trainer.train_all_models(X_train, y_train, X_test, y_test)\n",
    "    logging.info(\"Model training completed.\")\n",
    "\n",
    "    # Step 4: Model Evaluation\n",
    "    logging.info(\"Model evaluation started.\")\n",
    "    evaluator = ModelEvaluator()\n",
    "    logistic_errors = evaluator.error_analysis(trainer.train_model(\n",
    "        'Logistic Regression', X_train, y_train), X_test, y_test, test_x)\n",
    "    logging.info(\"Model evaluation completed.\")\n",
    "\n",
    "    # Show errors in the notebook\n",
    "    print(\"Logistic Regression errors:\")\n",
    "    display(logistic_errors)\n",
    "\n",
    "    # # Step 5: Model Tuning (optional)\n",
    "    # logging.info(\"Model tuning started.\")\n",
    "    # tuner = Tuner()\n",
    "    # rf_best_model, rf_best_params = tuner.tune_random_forest(X_train, y_train)\n",
    "    # logging.info(\n",
    "    #     f\"Random Forest tuning completed. Best parameters: {rf_best_params}\")\n",
    "\n",
    "    logging.info(\"Pipeline execution finished successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2024 07:42:08 PM INFO Pipeline execution started.\n",
      "[nltk_data] Downloading package twitter_samples to C:\\Users\\Hải\n",
      "[nltk_data]     Nam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "10/07/2024 07:42:09 PM INFO Data loading completed.\n",
      "10/07/2024 07:42:09 PM INFO Preprocessing started.\n",
      "10/07/2024 07:42:12 PM INFO Preprocessing finished.\n",
      "10/07/2024 07:42:12 PM INFO Model training started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      1000\n",
      "         1.0       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1000\n",
      "         1.0       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2024 07:42:20 PM INFO Model training completed.\n",
      "10/07/2024 07:42:20 PM INFO Model evaluation started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      1000\n",
      "         1.0       0.99      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96      1000\n",
      "         1.0       0.96      0.96      0.96      1000\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2024 07:42:20 PM INFO Model evaluation completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression errors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>real_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>[park, get, sunlight]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>[u, prob, fun, david]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>[pat, jay]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>[belov, grandmoth]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>[that, life, get, call, peopl, havent, seen, 2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>[sr, financi, analyst, expedia, inc, bellevu, ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  ...  real_class\n",
       "753                               [park, get, sunlight]  ...         1.0\n",
       "1298                              [u, prob, fun, david]  ...         0.0\n",
       "1544                                         [pat, jay]  ...         0.0\n",
       "1756                                 [belov, grandmoth]  ...         0.0\n",
       "1773  [that, life, get, call, peopl, havent, seen, 2...  ...         0.0\n",
       "1853  [sr, financi, analyst, expedia, inc, bellevu, ...  ...         0.0\n",
       "\n",
       "[6 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2024 07:42:20 PM INFO Pipeline execution finished successfully.\n"
     ]
    }
   ],
   "source": [
    "# Run the pipeline\n",
    "run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
